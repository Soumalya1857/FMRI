{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/titir/.local/lib/python3.8/site-packages/nilearn/datasets/__init__.py:93: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  warn(\"Fetchers from the nilearn.datasets module will be \"\n"
     ]
    }
   ],
   "source": [
    "from nilearn import image, plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rootdir = \"/home/sks/Documents/FMRI_Titir_Soumalya/25_Nov/ABIDE2_DATA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = \"/media/titir/Linux/Dataset_ABIDEII\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_filenames  = []\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "147\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for subdir, dir, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        filename = os.path.join(subdir, file)\n",
    "        #print(filename)\n",
    "        \n",
    "        if (filename.find('rest.nii.gz') != -1):\n",
    "            i = i + 1\n",
    "            if (i % 10) == 0:\n",
    "                print(i)\n",
    "            #smooth_img = image.smooth_img(filename, fwhm=3)\n",
    "            #print(smooth_img.shape)\n",
    "            #X_features.append(smooth_img)\n",
    "            fmri_filenames.append(filename)\n",
    "            \n",
    "\n",
    "print(len(fmri_filenames))       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features_np = np.array(X_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "print(len(X_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "print(X_features_np.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkpoint 1\n",
    "X_features have been extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fmri_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytarget = []\n",
    "with open(\"ABIDEII-BNI_1.csv\", 'r') as f:\n",
    "    mycsv = csv.reader(f)\n",
    "    for row in mycsv:\n",
    "        text = row[3] #dx_group\n",
    "        #print(text)\n",
    "        ytarget.append(text)\n",
    "ytarget = ytarget[1:]\n",
    "with open(\"ABIDEII-ETH_1.csv\", 'r') as f:\n",
    "    mycsv = csv.reader(f)\n",
    "    i = 0\n",
    "    for row in mycsv:\n",
    "        if i == 0:\n",
    "            i = i + 1\n",
    "            continue\n",
    "        text = row[3] #dx_group\n",
    "        #print(text)\n",
    "        ytarget.append(text)\n",
    "ytarget = ytarget[1:]\n",
    "with open(\"ABIDEII-EMC_1.csv\", 'r') as f:\n",
    "    mycsv = csv.reader(f)\n",
    "    i = 0\n",
    "    for row in mycsv:\n",
    "        if i == 0:\n",
    "            i = i + 1\n",
    "            continue\n",
    "        text = row[3] #dx_group\n",
    "        #print(text)\n",
    "        ytarget.append(text)\n",
    "ytarget = ytarget[1:]\n",
    "\n",
    "\n",
    "ytarget = [int(v) for v in ytarget]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/titir/Documents/Project Work/Dataset_ABIDEII/ABIDEII-ETH_1/29060/session_1/rest_1/rest.nii.gz\n"
     ]
    }
   ],
   "source": [
    "print(fmri_filenames[75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ytarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fmri_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytarget[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytarget = [int(v) for v in ytarget]\n",
    "ytarget_np = np.array(ytarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shuffle\n",
    "import random\n",
    "\n",
    "c = list(zip(X_features_cm, ytarget_np))\n",
    "\n",
    "random.shuffle(c)\n",
    "\n",
    "X, y = zip(*c)\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016\n"
     ]
    }
   ],
   "source": [
    "print(len(X[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "for i in range(len(X)):\n",
    "    if len(X[i]) != 2016:\n",
    "        index = i\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_arr = np.delete(X, np.where(len(X) != 2016))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.delete(y, index)\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "newX = []\n",
    "newY = []\n",
    "for i in range(50):\n",
    "    if len(X[i]) == 2016:\n",
    "        newX.append(X[i])\n",
    "        newY.append(y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_x = newX[:40]\n",
    "trainset_y = newY[:40]\n",
    "testset_x = newX[40:]\n",
    "testset_y = newY[40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "print(trainset_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clsf = svm.SVC()\n",
    "clsf.fit(trainset_x, trainset_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_correct = 0\n",
    "count_total  = 0\n",
    "for i in range(len(testset_y)):\n",
    "    ans = clsf.predict([testset_x[i]])\n",
    "    if ans == testset_y[i]:\n",
    "        count_correct = count_correct + 1\n",
    "    count_total = count_total + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_correct/count_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import datasets\n",
    "from nilearn.input_data import NiftiLabelsMasker\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numba in /home/titir/.local/lib/python3.8/site-packages (0.54.1)\n",
      "Requirement already satisfied: numpy<1.21,>=1.17 in /usr/lib/python3/dist-packages (from numba) (1.17.4)\n",
      "Requirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in /home/titir/.local/lib/python3.8/site-packages (from numba) (0.37.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from numba) (45.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit, cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished extracting 1 of 147\n",
      "finished extracting 2 of 147\n",
      "finished extracting 3 of 147\n",
      "finished extracting 4 of 147\n",
      "finished extracting 5 of 147\n",
      "finished extracting 6 of 147\n",
      "finished extracting 7 of 147\n",
      "finished extracting 8 of 147\n",
      "finished extracting 9 of 147\n",
      "finished extracting 10 of 147\n",
      "finished extracting 11 of 147\n",
      "finished extracting 12 of 147\n",
      "finished extracting 13 of 147\n",
      "finished extracting 14 of 147\n",
      "finished extracting 15 of 147\n",
      "finished extracting 16 of 147\n",
      "finished extracting 17 of 147\n",
      "finished extracting 18 of 147\n",
      "finished extracting 19 of 147\n",
      "finished extracting 20 of 147\n",
      "finished extracting 21 of 147\n",
      "finished extracting 22 of 147\n",
      "finished extracting 23 of 147\n",
      "finished extracting 24 of 147\n",
      "finished extracting 25 of 147\n",
      "finished extracting 26 of 147\n",
      "finished extracting 27 of 147\n",
      "finished extracting 28 of 147\n",
      "finished extracting 29 of 147\n",
      "finished extracting 30 of 147\n",
      "finished extracting 31 of 147\n",
      "finished extracting 32 of 147\n",
      "finished extracting 33 of 147\n",
      "finished extracting 34 of 147\n",
      "finished extracting 35 of 147\n",
      "finished extracting 36 of 147\n",
      "finished extracting 37 of 147\n",
      "finished extracting 38 of 147\n",
      "finished extracting 39 of 147\n",
      "finished extracting 40 of 147\n",
      "finished extracting 41 of 147\n",
      "finished extracting 42 of 147\n",
      "finished extracting 43 of 147\n",
      "finished extracting 44 of 147\n",
      "finished extracting 45 of 147\n",
      "finished extracting 46 of 147\n",
      "finished extracting 47 of 147\n",
      "finished extracting 48 of 147\n",
      "finished extracting 49 of 147\n",
      "finished extracting 50 of 147\n",
      "finished extracting 51 of 147\n",
      "finished extracting 52 of 147\n",
      "finished extracting 53 of 147\n",
      "finished extracting 54 of 147\n",
      "finished extracting 55 of 147\n",
      "finished extracting 56 of 147\n",
      "finished extracting 57 of 147\n",
      "finished extracting 58 of 147\n",
      "finished extracting 59 of 147\n",
      "finished extracting 60 of 147\n",
      "finished extracting 61 of 147\n",
      "finished extracting 62 of 147\n",
      "finished extracting 63 of 147\n",
      "finished extracting 64 of 147\n",
      "finished extracting 65 of 147\n",
      "finished extracting 66 of 147\n",
      "finished extracting 67 of 147\n",
      "finished extracting 68 of 147\n",
      "finished extracting 69 of 147\n",
      "finished extracting 70 of 147\n",
      "finished extracting 71 of 147\n",
      "finished extracting 72 of 147\n",
      "finished extracting 73 of 147\n",
      "finished extracting 74 of 147\n",
      "finished extracting 75 of 147\n",
      "finished extracting 76 of 147\n",
      "finished extracting 77 of 147\n",
      "finished extracting 78 of 147\n",
      "finished extracting 79 of 147\n",
      "finished extracting 80 of 147\n",
      "finished extracting 81 of 147\n",
      "finished extracting 82 of 147\n",
      "finished extracting 83 of 147\n",
      "finished extracting 84 of 147\n",
      "finished extracting 85 of 147\n",
      "finished extracting 86 of 147\n",
      "finished extracting 87 of 147\n",
      "finished extracting 88 of 147\n",
      "finished extracting 89 of 147\n",
      "finished extracting 90 of 147\n",
      "finished extracting 91 of 147\n",
      "finished extracting 92 of 147\n",
      "finished extracting 93 of 147\n",
      "finished extracting 94 of 147\n",
      "finished extracting 95 of 147\n",
      "finished extracting 96 of 147\n",
      "finished extracting 97 of 147\n",
      "finished extracting 98 of 147\n",
      "finished extracting 99 of 147\n",
      "finished extracting 100 of 147\n",
      "finished extracting 101 of 147\n",
      "finished extracting 102 of 147\n",
      "finished extracting 103 of 147\n",
      "finished extracting 104 of 147\n",
      "finished extracting 105 of 147\n",
      "finished extracting 106 of 147\n",
      "finished extracting 107 of 147\n",
      "finished extracting 108 of 147\n",
      "finished extracting 109 of 147\n",
      "finished extracting 110 of 147\n",
      "finished extracting 111 of 147\n",
      "finished extracting 112 of 147\n",
      "finished extracting 113 of 147\n",
      "finished extracting 114 of 147\n",
      "finished extracting 115 of 147\n",
      "finished extracting 116 of 147\n",
      "finished extracting 117 of 147\n",
      "finished extracting 118 of 147\n",
      "finished extracting 119 of 147\n",
      "finished extracting 120 of 147\n",
      "finished extracting 121 of 147\n",
      "finished extracting 122 of 147\n",
      "finished extracting 123 of 147\n",
      "finished extracting 124 of 147\n",
      "finished extracting 125 of 147\n",
      "finished extracting 126 of 147\n",
      "finished extracting 127 of 147\n",
      "finished extracting 128 of 147\n",
      "finished extracting 129 of 147\n",
      "finished extracting 130 of 147\n",
      "finished extracting 131 of 147\n",
      "finished extracting 132 of 147\n",
      "finished extracting 133 of 147\n",
      "finished extracting 134 of 147\n",
      "finished extracting 135 of 147\n",
      "finished extracting 136 of 147\n",
      "finished extracting 137 of 147\n",
      "finished extracting 138 of 147\n",
      "finished extracting 139 of 147\n",
      "finished extracting 140 of 147\n",
      "finished extracting 141 of 147\n",
      "finished extracting 142 of 147\n",
      "finished extracting 143 of 147\n",
      "finished extracting 144 of 147\n",
      "finished extracting 145 of 147\n",
      "finished extracting 146 of 147\n",
      "finished extracting 147 of 147\n"
     ]
    }
   ],
   "source": [
    "def prepare_data():\n",
    "    multiscale = datasets.fetch_atlas_basc_multiscale_2015()\n",
    "    atlas_filename = multiscale.scale064\n",
    "\n",
    "    # initialize masker object\n",
    "    masker = NiftiLabelsMasker(labels_img=atlas_filename,\n",
    "                               standardize=True,\n",
    "                               memory='nilearn_cache',\n",
    "                               verbose=0)\n",
    "\n",
    "    # initialize correlation measure\n",
    "    correlation_measure = ConnectivityMeasure(kind='correlation', vectorize=True,\n",
    "                                             discard_diagonal=True)\n",
    "    \n",
    "    X_features_cm = []\n",
    "    \n",
    "    for i,sub in enumerate(fmri_filenames):\n",
    "            # extract the timeseries from the ROIs in the atlas\n",
    "            time_series = masker.fit_transform(sub)\n",
    "            # create a region x region correlation matrix\n",
    "            correlation_matrix = correlation_measure.fit_transform([time_series])[0]\n",
    "            # add to our container\n",
    "            X_features_cm.append(correlation_matrix)\n",
    "            # keep track of status\n",
    "            print('finished extracting %s of %s'%(i+1,len(fmri_filenames)))\n",
    "            \n",
    "    # Dimensionality reduction of features with PCA\n",
    "    \n",
    "    \n",
    "    return X_features_cm\n",
    "X_features_cm = prepare_data()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/titir/nilearn_data/ABIDE_pcp/cpac/nofilt_noglobal/Pitt_0050003_func_preproc.nii.gz']\n",
      "0\n",
      "/home/titir/nilearn_data/ABIDE_pcp/cpac/nofilt_noglobal/Pitt_0050003_func_preproc.nii.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/numpy/lib/npyio.py:2358: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  output = genfromtxt(fname, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "abide = datasets.fetch_abide_pcp(\n",
    "                                 pipeline = \"cpac\",\n",
    "                                 quality_checked = True, \n",
    "                                 n_subjects=1)\n",
    "# make list of filenames\n",
    "fmri_filenames_t = abide.func_preproc\n",
    "print(fmri_filenames_t)\n",
    "for i,sub in enumerate(fmri_filenames_t):\n",
    "    print(i)\n",
    "    print(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features_cm = list([list(element) for element in X_features_cm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "1770\n",
      "2016\n",
      "2016\n",
      "1830\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "1953\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "1653\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "1326\n",
      "2016\n",
      "1953\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "1711\n",
      "1770\n",
      "1830\n",
      "1891\n",
      "2016\n",
      "1540\n",
      "2016\n",
      "1830\n",
      "2016\n",
      "2016\n",
      "1711\n",
      "1953\n",
      "2016\n",
      "1953\n",
      "1891\n",
      "2016\n",
      "2016\n",
      "1830\n",
      "1830\n",
      "2016\n",
      "1953\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "1770\n",
      "2016\n",
      "2016\n",
      "1431\n",
      "1830\n",
      "1953\n",
      "1953\n",
      "2016\n",
      "2016\n",
      "1830\n",
      "2016\n",
      "2016\n",
      "1891\n",
      "2016\n",
      "1431\n",
      "2016\n",
      "1770\n",
      "2016\n",
      "2016\n",
      "1711\n",
      "1953\n",
      "1830\n",
      "2016\n",
      "1653\n",
      "1711\n",
      "1596\n",
      "1653\n",
      "2016\n",
      "1891\n"
     ]
    }
   ],
   "source": [
    "for arr in X_features_cm:\n",
    "    print(len(arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running SVM on ABIDE 2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import random\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "random.seed(datetime.datetime.now())\n",
    "\n",
    "newX = []\n",
    "newY = []\n",
    "for i in range(len(X)):\n",
    "    if len(X[i]) == 2016:\n",
    "        newX.append(X[i])\n",
    "        newY.append(y[i])\n",
    "#print(len(newX))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCA...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "print(\"Running PCA...\")\n",
    "pca = PCA(0.99).fit(newX)\n",
    "newX_pca =  pca.transform(newX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_X, testset_X, trainset_Y, testset_Y = train_test_split(newX, newY, test_size=0.3, random_state=103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.5882352941176471\n",
      "Precision 0.5333333333333333\n",
      "Recall 0.5333333333333333\n"
     ]
    }
   ],
   "source": [
    "clsf_svc = svm.SVC(kernel=\"linear\", C=2)\n",
    "clsf_svc.fit(trainset_X, trainset_Y)\n",
    "\n",
    "y_pred = clsf_svc.predict(testset_X)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "accuracy = metrics.accuracy_score(testset_Y, y_pred)\n",
    "precision = metrics.precision_score(testset_Y, y_pred)\n",
    "recall = metrics.recall_score(testset_Y, y_pred)\n",
    "\n",
    "print(\"Accuracy\", accuracy)\n",
    "print(\"Precision\", precision)\n",
    "print(\"Recall\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.5294117647058824\n",
      "Precision 0.4444444444444444\n",
      "Recall 0.26666666666666666\n",
      "[[ 4 11]\n",
      " [ 5 14]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/titir/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f8f5bedd280>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clsf = svm.SVC(kernel=\"sigmoid\", C=2)   ## C=3 gave higher values of accuracy!\n",
    "clsf.fit(trainset_X, trainset_Y)\n",
    "\n",
    "y_pred = clsf.predict(testset_X)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "accuracy = metrics.accuracy_score(testset_Y, y_pred)\n",
    "precision = metrics.precision_score(testset_Y, y_pred)\n",
    "recall = metrics.recall_score(testset_Y, y_pred)\n",
    "\n",
    "print(\"Accuracy\", accuracy)\n",
    "print(\"Precision\", precision)\n",
    "print(\"Recall\", recall)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "print(str(confusion_matrix(testset_Y, y_pred)))\n",
    "plot_confusion_matrix(clsf, testset_X, testset_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params = {\n",
    "    'kernel': ['sigmoid', 'poly', 'linear', 'rbf'],\n",
    "    'C': [1, 2, 3, 4]\n",
    "    \n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "gs_svc = GridSearchCV(svm.SVC(),\n",
    "        grid_params,\n",
    "        scoring='accuracy',\n",
    "        cv=5\n",
    "        )\n",
    "\n",
    "gs_results = gs_svc.fit(trainset_X, trainset_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=3, kernel='linear')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_svc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5975"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_svc.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.6764705882352942\n",
      "Precision 0.625\n",
      "Recall 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clsf_ls = LinearSVC(dual=False, random_state=0, penalty=\"l2\", max_iter=10000)\n",
    "clsf_ls.fit(trainset_X, trainset_Y)\n",
    "\n",
    "y_pred = clsf_ls.predict(testset_X)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "accuracy = metrics.accuracy_score(testset_Y, y_pred)\n",
    "precision = metrics.precision_score(testset_Y, y_pred)\n",
    "recall = metrics.recall_score(testset_Y, y_pred)\n",
    "\n",
    "print(\"Accuracy\", accuracy)\n",
    "print(\"Precision\", precision)\n",
    "print(\"Recall\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Logistic Regression on ABIDE 2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.6764705882352942\n",
      "Precision 0.6111111111111112\n",
      "Recall 0.7333333333333333\n",
      "[[11  4]\n",
      " [ 7 12]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/titir/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f8f5bf59730>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clsf_lg = LogisticRegression(penalty='none')\n",
    "clsf_lg.fit(trainset_X, trainset_Y)\n",
    "\n",
    "y_pred = clsf_lg.predict(testset_X)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "accuracy = metrics.accuracy_score(testset_Y, y_pred)\n",
    "precision = metrics.precision_score(testset_Y, y_pred)\n",
    "recall = metrics.recall_score(testset_Y, y_pred)\n",
    "\n",
    "print(\"Accuracy\", accuracy)\n",
    "print(\"Precision\", precision)\n",
    "print(\"Recall\", recall)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "print(str(confusion_matrix(testset_Y, y_pred)))\n",
    "plot_confusion_matrix(clsf, testset_X, testset_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running a Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.7941176470588235\n",
      "Precision 0.7222222222222222\n",
      "Recall 0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "# TODO\n",
    "clsf_rf = RandomForestClassifier()\n",
    "clsf_rf.fit(trainset_X, trainset_Y)\n",
    "\n",
    "y_pred = clsf_rf.predict(testset_X)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "accuracy = metrics.accuracy_score(testset_Y, y_pred)\n",
    "precision = metrics.precision_score(testset_Y, y_pred)\n",
    "recall = metrics.recall_score(testset_Y, y_pred)\n",
    "\n",
    "print(\"Accuracy\", accuracy)\n",
    "print(\"Precision\", precision)\n",
    "print(\"Recall\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=90, n_estimators=80)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_params_rf = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'n_estimators': [80, 90, 100, 110]\n",
    "    \n",
    "}\n",
    "\n",
    "gs_rf = GridSearchCV(RandomForestClassifier(),\n",
    "                        grid_params_rf,\n",
    "                        scoring='accuracy')\n",
    "\n",
    "gs_results_rf = gs_rf.fit(trainset_X, trainset_Y)\n",
    "gs_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6358333333333334"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.6176470588235294\n",
      "Precision 0.5625\n",
      "Recall 0.6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "clsf_dt = DecisionTreeClassifier() \n",
    "clsf_dt.fit(trainset_X, trainset_Y)\n",
    "\n",
    "y_pred = clsf_dt.predict(testset_X)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "accuracy = metrics.accuracy_score(testset_Y, y_pred)\n",
    "precision = metrics.precision_score(testset_Y, y_pred)\n",
    "recall = metrics.recall_score(testset_Y, y_pred)\n",
    "\n",
    "print(\"Accuracy\", accuracy)\n",
    "print(\"Precision\", precision)\n",
    "print(\"Recall\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.5882352941176471\n",
      "Precision 0.5294117647058824\n",
      "Recall 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/titir/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f8f59d0db20>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB, BernoulliNB, CategoricalNB\n",
    "clsf_nb = GaussianNB() ## gives best accuracy of all the different naive bayes approaches\n",
    "clsf_nb.fit(trainset_X, trainset_Y)\n",
    "\n",
    "y_pred = clsf_nb.predict(testset_X)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "accuracy = metrics.accuracy_score(testset_Y, y_pred)\n",
    "precision = metrics.precision_score(testset_Y, y_pred)\n",
    "recall = metrics.recall_score(testset_Y, y_pred)\n",
    "\n",
    "print(\"Accuracy\", accuracy)\n",
    "print(\"Precision\", precision)\n",
    "print(\"Recall\", recall)\n",
    "\n",
    "plot_confusion_matrix(clsf, testset_X, testset_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.6176470588235294\n",
      "Precision 0.6\n",
      "Recall 0.4\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from math import sqrt\n",
    "\n",
    "k = int(sqrt(len(trainset_X)))\n",
    "clsf = KNeighborsClassifier(n_neighbors=14) \n",
    "clsf.fit(trainset_X, trainset_Y)\n",
    "\n",
    "y_pred = clsf.predict(testset_X)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "accuracy = metrics.accuracy_score(testset_Y, y_pred)\n",
    "precision = metrics.precision_score(testset_Y, y_pred)\n",
    "recall = metrics.recall_score(testset_Y, y_pred)\n",
    "\n",
    "print(\"Accuracy\", accuracy)\n",
    "print(\"Precision\", precision)\n",
    "print(\"Recall\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.6764705882352942\n",
      "Precision 0.6111111111111112\n",
      "Recall 0.7333333333333333\n",
      "[[11  4]\n",
      " [ 7 12]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/titir/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f8f5a644340>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clsf = LogisticRegression(penalty='none')\n",
    "clsf.fit(trainset_X, trainset_Y)\n",
    "\n",
    "y_pred = clsf.predict(testset_X)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "accuracy = metrics.accuracy_score(testset_Y, y_pred)\n",
    "precision = metrics.precision_score(testset_Y, y_pred)\n",
    "recall = metrics.recall_score(testset_Y, y_pred)\n",
    "\n",
    "print(\"Accuracy\", accuracy)\n",
    "print(\"Precision\", precision)\n",
    "print(\"Recall\", recall)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "print(str(confusion_matrix(testset_Y, y_pred)))\n",
    "plot_confusion_matrix(clsf, testset_X, testset_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying a grid search with KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "k = [i for i in range(1, 15, 2)]\n",
    "grid_params_knn = {\n",
    "    'n_neighbors': k,\n",
    "    'weights': ['uniform', 'distance'] ,\n",
    "    'metric': ['minkowski', 'manhattan'] \n",
    "}\n",
    "\n",
    "gs_knn = GridSearchCV(KNeighborsClassifier(),\n",
    "        grid_params_knn,\n",
    "        scoring='accuracy',\n",
    "        )\n",
    "\n",
    "gs_results_knn = gs_knn.fit(trainset_X, trainset_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5349999999999999"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_knn.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_knn.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': 'minkowski', 'n_neighbors': 1, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_knn.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.5882352941176471\n",
      "Precision 0.5294117647058824\n",
      "Recall 0.6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier, MLPRegressor, BernoulliRBM\n",
    "\n",
    "clsf_mlp = MLPClassifier(learning_rate='adaptive', max_iter=10000)\n",
    "clsf_mlp.fit(trainset_X, trainset_Y)\n",
    "\n",
    "y_pred = clsf_mlp.predict(testset_X)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "accuracy = metrics.accuracy_score(testset_Y, y_pred)\n",
    "precision = metrics.precision_score(testset_Y, y_pred)\n",
    "recall = metrics.recall_score(testset_Y, y_pred)\n",
    "\n",
    "print(\"Accuracy\", accuracy)\n",
    "print(\"Precision\", precision)\n",
    "print(\"Recall\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params_mlp = {\n",
    "    'activation': ['tanh', 'relu', 'logistic'],\n",
    "    'solver': ['sgd', 'adam', 'lbfgs'], \n",
    "    'max_iter': [500, 1000, 10000],\n",
    "    'early_stopping': [True]\n",
    "    \n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "gs_mlp = GridSearchCV(MLPClassifier(),\n",
    "        grid_params_mlp,\n",
    "        scoring='accuracy',\n",
    "        )\n",
    "\n",
    "gs_results_mlp = gs_mlp.fit(trainset_X, trainset_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', early_stopping=True, max_iter=1000,\n",
       "              solver='lbfgs')"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_mlp.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6358333333333333"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_mlp.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers we have right now \n",
    "* MLP\n",
    "* Random Forests\n",
    "* Naive Bayes\n",
    "* KNN\n",
    "* SVC\n",
    "* Linear SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "gs_svc.best_estimator_,\n",
    "clsf_ls,\n",
    "clsf_lg,\n",
    "clsf_rf,\n",
    "clsf_dt,\n",
    "clsf_nb,\n",
    "gs_knn.best_estimator_,\n",
    "gs_mlp.best_estimator_]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_mode_classifier_result(newX):\n",
    "    X_features_nn = []\n",
    "    X_mode = []\n",
    "    \n",
    "    for x in newX:\n",
    "        if (len(x) == 2016):\n",
    "            nv = []\n",
    "            for clsf in classifiers:\n",
    "                nv.append(clsf.predict([x]))\n",
    "\n",
    "            X_features_nn.append(nv)\n",
    "            #print(type(nv))\n",
    "            nv_list = list(nv)\n",
    "            val = max(nv_list, key=nv_list.count)\n",
    "            X_mode.append(val)\n",
    "    return (X_features_nn, X_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_features_nn, y_pred_mode) = find_mode_classifier_result(trainset_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy from calculating the mode of the result of all the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(trainset_Y, y_pred_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_features_nn[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addding a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Activation\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=8, activation='relu'))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "X_train = normalize(np.reshape(np.array(X_features_nn), (77, 8)))\n",
    "Y_train = np.array(trainset_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.2783 - accuracy: 0.4935\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.2798 - accuracy: 0.4935\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.2814 - accuracy: 0.4935\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.2829 - accuracy: 0.4935\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.2843 - accuracy: 0.4935\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.2858 - accuracy: 0.4935\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.2873 - accuracy: 0.4935\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.2888 - accuracy: 0.4935\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: -1.2902 - accuracy: 0.4935\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.2917 - accuracy: 0.4935\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.2932 - accuracy: 0.4935\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.2947 - accuracy: 0.4935\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.2961 - accuracy: 0.4935\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.2976 - accuracy: 0.4935\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.2991 - accuracy: 0.4935\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3006 - accuracy: 0.4935\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3020 - accuracy: 0.4935\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3035 - accuracy: 0.4935\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.3050 - accuracy: 0.4935\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3065 - accuracy: 0.4935\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3079 - accuracy: 0.4935\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3094 - accuracy: 0.4935\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3108 - accuracy: 0.4935\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3123 - accuracy: 0.4935\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3137 - accuracy: 0.4935\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3152 - accuracy: 0.4935\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3167 - accuracy: 0.4935\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3182 - accuracy: 0.4935\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3196 - accuracy: 0.4935\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3211 - accuracy: 0.4935\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3226 - accuracy: 0.4935\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 6ms/step - loss: -1.3241 - accuracy: 0.4935\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3256 - accuracy: 0.4935\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3270 - accuracy: 0.4935\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3286 - accuracy: 0.4935\n",
      "Epoch 36/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3300 - accuracy: 0.4935\n",
      "Epoch 37/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3316 - accuracy: 0.4935\n",
      "Epoch 38/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3331 - accuracy: 0.4935\n",
      "Epoch 39/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3345 - accuracy: 0.4935\n",
      "Epoch 40/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.3360 - accuracy: 0.4935\n",
      "Epoch 41/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3375 - accuracy: 0.4935\n",
      "Epoch 42/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3390 - accuracy: 0.4935\n",
      "Epoch 43/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3404 - accuracy: 0.4935\n",
      "Epoch 44/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3419 - accuracy: 0.4935\n",
      "Epoch 45/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3433 - accuracy: 0.4935\n",
      "Epoch 46/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.3447 - accuracy: 0.4935\n",
      "Epoch 47/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3463 - accuracy: 0.4935\n",
      "Epoch 48/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3477 - accuracy: 0.4935\n",
      "Epoch 49/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3492 - accuracy: 0.4935\n",
      "Epoch 50/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3507 - accuracy: 0.4935\n",
      "Epoch 51/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3522 - accuracy: 0.4935\n",
      "Epoch 52/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3537 - accuracy: 0.4935\n",
      "Epoch 53/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.3552 - accuracy: 0.4935\n",
      "Epoch 54/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3567 - accuracy: 0.4935\n",
      "Epoch 55/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3581 - accuracy: 0.4935\n",
      "Epoch 56/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3596 - accuracy: 0.4935\n",
      "Epoch 57/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3610 - accuracy: 0.4935\n",
      "Epoch 58/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3626 - accuracy: 0.4935\n",
      "Epoch 59/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3641 - accuracy: 0.4935\n",
      "Epoch 60/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3655 - accuracy: 0.4935\n",
      "Epoch 61/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3670 - accuracy: 0.4935\n",
      "Epoch 62/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3685 - accuracy: 0.4935\n",
      "Epoch 63/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3699 - accuracy: 0.4935\n",
      "Epoch 64/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3714 - accuracy: 0.4935\n",
      "Epoch 65/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.3729 - accuracy: 0.4935\n",
      "Epoch 66/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.3743 - accuracy: 0.4935\n",
      "Epoch 67/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3757 - accuracy: 0.4935\n",
      "Epoch 68/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3773 - accuracy: 0.4935\n",
      "Epoch 69/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3786 - accuracy: 0.4935\n",
      "Epoch 70/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3801 - accuracy: 0.4935\n",
      "Epoch 71/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3816 - accuracy: 0.4935\n",
      "Epoch 72/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3830 - accuracy: 0.4935\n",
      "Epoch 73/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3844 - accuracy: 0.4935\n",
      "Epoch 74/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3858 - accuracy: 0.4935\n",
      "Epoch 75/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3872 - accuracy: 0.4935\n",
      "Epoch 76/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3887 - accuracy: 0.4935\n",
      "Epoch 77/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3902 - accuracy: 0.4935\n",
      "Epoch 78/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.3916 - accuracy: 0.4935\n",
      "Epoch 79/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3930 - accuracy: 0.4935\n",
      "Epoch 80/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3944 - accuracy: 0.4935\n",
      "Epoch 81/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.3959 - accuracy: 0.4935\n",
      "Epoch 82/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3974 - accuracy: 0.4935\n",
      "Epoch 83/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.3989 - accuracy: 0.4935\n",
      "Epoch 84/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.4004 - accuracy: 0.4935\n",
      "Epoch 85/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.4019 - accuracy: 0.4935\n",
      "Epoch 86/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.4034 - accuracy: 0.4935\n",
      "Epoch 87/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.4048 - accuracy: 0.4935\n",
      "Epoch 88/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.4064 - accuracy: 0.4935\n",
      "Epoch 89/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.4078 - accuracy: 0.4935\n",
      "Epoch 90/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.4093 - accuracy: 0.4935\n",
      "Epoch 91/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.4108 - accuracy: 0.4935\n",
      "Epoch 92/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.4122 - accuracy: 0.4935\n",
      "Epoch 93/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.4137 - accuracy: 0.4935\n",
      "Epoch 94/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.4151 - accuracy: 0.4935\n",
      "Epoch 95/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.4166 - accuracy: 0.4935\n",
      "Epoch 96/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.4180 - accuracy: 0.4935\n",
      "Epoch 97/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.4195 - accuracy: 0.4935\n",
      "Epoch 98/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.4210 - accuracy: 0.4935\n",
      "Epoch 99/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.4224 - accuracy: 0.4935\n",
      "Epoch 100/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.4239 - accuracy: 0.4935\n",
      "Epoch 101/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.4254 - accuracy: 0.4935\n",
      "Epoch 102/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.4270 - accuracy: 0.4935\n",
      "Epoch 103/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.4284 - accuracy: 0.4935\n",
      "Epoch 104/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.4299 - accuracy: 0.4935\n",
      "Epoch 105/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.4313 - accuracy: 0.4935\n",
      "Epoch 106/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.4328 - accuracy: 0.4935\n",
      "Epoch 107/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.4342 - accuracy: 0.4935\n",
      "Epoch 108/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.4357 - accuracy: 0.4935\n",
      "Epoch 109/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.4372 - accuracy: 0.4935\n",
      "Epoch 110/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.4386 - accuracy: 0.4935\n",
      "Epoch 111/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.4401 - accuracy: 0.4935\n",
      "Epoch 112/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.4415 - accuracy: 0.4935\n",
      "Epoch 113/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.4430 - accuracy: 0.4935\n",
      "Epoch 114/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.4444 - accuracy: 0.4935\n",
      "Epoch 115/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.4459 - accuracy: 0.4935\n",
      "Epoch 116/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.4473 - accuracy: 0.4935\n",
      "Epoch 117/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.4488 - accuracy: 0.4935\n",
      "Epoch 118/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.4503 - accuracy: 0.4935\n",
      "Epoch 119/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.4517 - accuracy: 0.4935\n",
      "Epoch 120/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.4533 - accuracy: 0.4935\n",
      "Epoch 121/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: -1.4548 - accuracy: 0.4935\n",
      "Epoch 122/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.4563 - accuracy: 0.4935\n",
      "Epoch 123/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: -1.4578 - accuracy: 0.4935\n",
      "Epoch 124/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.4592 - accuracy: 0.4935\n",
      "Epoch 125/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.4607 - accuracy: 0.4935\n",
      "Epoch 126/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.4622 - accuracy: 0.4935\n",
      "Epoch 127/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.4636 - accuracy: 0.4935\n",
      "Epoch 128/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: -1.4650 - accuracy: 0.4935\n",
      "Epoch 129/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.4665 - accuracy: 0.4935\n",
      "Epoch 130/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: -1.4679 - accuracy: 0.4935\n",
      "Epoch 131/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.4693 - accuracy: 0.4935\n",
      "Epoch 132/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.4708 - accuracy: 0.4935\n",
      "Epoch 133/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: -1.4722 - accuracy: 0.4935\n",
      "Epoch 134/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.4737 - accuracy: 0.4935\n",
      "Epoch 135/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.4750 - accuracy: 0.4935\n",
      "Epoch 136/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: -1.4765 - accuracy: 0.4935\n",
      "Epoch 137/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: -1.4780 - accuracy: 0.4935\n",
      "Epoch 138/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.4795 - accuracy: 0.4935\n",
      "Epoch 139/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: -1.4810 - accuracy: 0.4935\n",
      "Epoch 140/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: -1.4824 - accuracy: 0.4935\n",
      "Epoch 141/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.4839 - accuracy: 0.4935\n",
      "Epoch 142/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: -1.4854 - accuracy: 0.4935\n",
      "Epoch 143/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: -1.4869 - accuracy: 0.4935\n",
      "Epoch 144/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: -1.4883 - accuracy: 0.4935\n",
      "Epoch 145/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: -1.4898 - accuracy: 0.4935\n",
      "Epoch 146/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: -1.4913 - accuracy: 0.4935\n",
      "Epoch 147/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.4927 - accuracy: 0.4935\n",
      "Epoch 148/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: -1.4942 - accuracy: 0.4935\n",
      "Epoch 149/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: -1.4956 - accuracy: 0.4935\n",
      "Epoch 150/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.4971 - accuracy: 0.4935\n",
      "Epoch 151/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.4985 - accuracy: 0.4935\n",
      "Epoch 152/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.4999 - accuracy: 0.4935\n",
      "Epoch 153/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.5014 - accuracy: 0.4935\n",
      "Epoch 154/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.5029 - accuracy: 0.4935\n",
      "Epoch 155/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5044 - accuracy: 0.4935\n",
      "Epoch 156/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5058 - accuracy: 0.4935\n",
      "Epoch 157/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5072 - accuracy: 0.4935\n",
      "Epoch 158/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.5087 - accuracy: 0.4935\n",
      "Epoch 159/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5101 - accuracy: 0.4935\n",
      "Epoch 160/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5115 - accuracy: 0.4935\n",
      "Epoch 161/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5130 - accuracy: 0.4935\n",
      "Epoch 162/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5144 - accuracy: 0.4935\n",
      "Epoch 163/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5158 - accuracy: 0.4935\n",
      "Epoch 164/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5173 - accuracy: 0.4935\n",
      "Epoch 165/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.5186 - accuracy: 0.4935\n",
      "Epoch 166/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5201 - accuracy: 0.4935\n",
      "Epoch 167/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5215 - accuracy: 0.4935\n",
      "Epoch 168/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5229 - accuracy: 0.4935\n",
      "Epoch 169/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.5243 - accuracy: 0.4935\n",
      "Epoch 170/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: -1.5257 - accuracy: 0.4935\n",
      "Epoch 171/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5272 - accuracy: 0.4935\n",
      "Epoch 172/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5286 - accuracy: 0.4935\n",
      "Epoch 173/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5300 - accuracy: 0.4935\n",
      "Epoch 174/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5315 - accuracy: 0.4935\n",
      "Epoch 175/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5330 - accuracy: 0.4935\n",
      "Epoch 176/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5344 - accuracy: 0.4935\n",
      "Epoch 177/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5358 - accuracy: 0.4935\n",
      "Epoch 178/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5373 - accuracy: 0.4935\n",
      "Epoch 179/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5388 - accuracy: 0.4935\n",
      "Epoch 180/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.5402 - accuracy: 0.4935\n",
      "Epoch 181/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5417 - accuracy: 0.4935\n",
      "Epoch 182/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5432 - accuracy: 0.4935\n",
      "Epoch 183/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5446 - accuracy: 0.4935\n",
      "Epoch 184/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5460 - accuracy: 0.4935\n",
      "Epoch 185/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5475 - accuracy: 0.4935\n",
      "Epoch 186/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5490 - accuracy: 0.4935\n",
      "Epoch 187/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5505 - accuracy: 0.4935\n",
      "Epoch 188/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5518 - accuracy: 0.4935\n",
      "Epoch 189/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5533 - accuracy: 0.4935\n",
      "Epoch 190/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5547 - accuracy: 0.4935\n",
      "Epoch 191/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: -1.5562 - accuracy: 0.4935\n",
      "Epoch 192/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5576 - accuracy: 0.4935\n",
      "Epoch 193/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5590 - accuracy: 0.4935\n",
      "Epoch 194/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5605 - accuracy: 0.4935\n",
      "Epoch 195/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5619 - accuracy: 0.4935\n",
      "Epoch 196/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5633 - accuracy: 0.4935\n",
      "Epoch 197/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5648 - accuracy: 0.4935\n",
      "Epoch 198/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5661 - accuracy: 0.4935\n",
      "Epoch 199/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5675 - accuracy: 0.4935\n",
      "Epoch 200/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5689 - accuracy: 0.4935\n",
      "Epoch 201/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5704 - accuracy: 0.4935\n",
      "Epoch 202/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5718 - accuracy: 0.4935\n",
      "Epoch 203/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5732 - accuracy: 0.4935\n",
      "Epoch 204/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5747 - accuracy: 0.4935\n",
      "Epoch 205/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5761 - accuracy: 0.4935\n",
      "Epoch 206/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5777 - accuracy: 0.4935\n",
      "Epoch 207/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5791 - accuracy: 0.4935\n",
      "Epoch 208/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5806 - accuracy: 0.4935\n",
      "Epoch 209/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5821 - accuracy: 0.4935\n",
      "Epoch 210/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5836 - accuracy: 0.4935\n",
      "Epoch 211/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5850 - accuracy: 0.4935\n",
      "Epoch 212/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5865 - accuracy: 0.4935\n",
      "Epoch 213/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.5880 - accuracy: 0.4935\n",
      "Epoch 214/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5895 - accuracy: 0.4935\n",
      "Epoch 215/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5909 - accuracy: 0.4935\n",
      "Epoch 216/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5924 - accuracy: 0.4935\n",
      "Epoch 217/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5938 - accuracy: 0.4935\n",
      "Epoch 218/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5953 - accuracy: 0.4935\n",
      "Epoch 219/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5968 - accuracy: 0.4935\n",
      "Epoch 220/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.5982 - accuracy: 0.4935\n",
      "Epoch 221/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.5997 - accuracy: 0.4935\n",
      "Epoch 222/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.6012 - accuracy: 0.4935\n",
      "Epoch 223/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.6026 - accuracy: 0.4935\n",
      "Epoch 224/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.6041 - accuracy: 0.4935\n",
      "Epoch 225/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.6055 - accuracy: 0.4935\n",
      "Epoch 226/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.6070 - accuracy: 0.4935\n",
      "Epoch 227/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: -1.6085 - accuracy: 0.4935\n",
      "Epoch 228/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.6098 - accuracy: 0.4935\n",
      "Epoch 229/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.6113 - accuracy: 0.4935\n",
      "Epoch 230/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.6128 - accuracy: 0.4935\n",
      "Epoch 231/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.6142 - accuracy: 0.4935\n",
      "Epoch 232/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.6155 - accuracy: 0.4935\n",
      "Epoch 233/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.6170 - accuracy: 0.4935\n",
      "Epoch 234/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.6184 - accuracy: 0.4935\n",
      "Epoch 235/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.6197 - accuracy: 0.4935\n",
      "Epoch 236/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.6212 - accuracy: 0.4935\n",
      "Epoch 237/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.6226 - accuracy: 0.4935\n",
      "Epoch 238/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.6240 - accuracy: 0.4935\n",
      "Epoch 239/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.6254 - accuracy: 0.4935\n",
      "Epoch 240/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.6268 - accuracy: 0.4935\n",
      "Epoch 241/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.6282 - accuracy: 0.4935\n",
      "Epoch 242/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.6296 - accuracy: 0.4935\n",
      "Epoch 243/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.6309 - accuracy: 0.4935\n",
      "Epoch 244/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.6324 - accuracy: 0.4935\n",
      "Epoch 245/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.6339 - accuracy: 0.4935\n",
      "Epoch 246/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.6353 - accuracy: 0.4935\n",
      "Epoch 247/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.6368 - accuracy: 0.4935\n",
      "Epoch 248/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.6382 - accuracy: 0.4935\n",
      "Epoch 249/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.6397 - accuracy: 0.4935\n",
      "Epoch 250/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.6412 - accuracy: 0.4935\n",
      "Epoch 251/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.6427 - accuracy: 0.4935\n",
      "Epoch 252/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.6441 - accuracy: 0.4935\n",
      "Epoch 253/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.6455 - accuracy: 0.4935\n",
      "Epoch 254/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.6470 - accuracy: 0.4935\n",
      "Epoch 255/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.6484 - accuracy: 0.4935\n",
      "Epoch 256/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.6498 - accuracy: 0.4935\n",
      "Epoch 257/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.6514 - accuracy: 0.4935\n",
      "Epoch 258/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.6528 - accuracy: 0.4935\n",
      "Epoch 259/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.6542 - accuracy: 0.4935\n",
      "Epoch 260/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.6556 - accuracy: 0.4935\n",
      "Epoch 261/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.6571 - accuracy: 0.4935\n",
      "Epoch 262/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: -1.6585 - accuracy: 0.4935\n",
      "Epoch 263/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.6599 - accuracy: 0.4935\n",
      "Epoch 264/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: -1.6614 - accuracy: 0.4935\n",
      "Epoch 265/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: -1.6629 - accuracy: 0.4935\n",
      "Epoch 266/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.6644 - accuracy: 0.4935\n",
      "Epoch 267/1000\n",
      "3/3 [==============================] - 0s 6ms/step - loss: -1.6657 - accuracy: 0.4935\n",
      "Epoch 268/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.6673 - accuracy: 0.4935\n",
      "Epoch 269/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.6687 - accuracy: 0.4935\n",
      "Epoch 270/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.6702 - accuracy: 0.4935\n",
      "Epoch 271/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.6716 - accuracy: 0.4935\n",
      "Epoch 272/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.6730 - accuracy: 0.4935\n",
      "Epoch 273/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.6745 - accuracy: 0.4935\n",
      "Epoch 274/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.6759 - accuracy: 0.4935\n",
      "Epoch 275/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.6773 - accuracy: 0.4935\n",
      "Epoch 276/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.6788 - accuracy: 0.4935\n",
      "Epoch 277/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.6802 - accuracy: 0.4935\n",
      "Epoch 278/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.6816 - accuracy: 0.4935\n",
      "Epoch 279/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.6831 - accuracy: 0.4935\n",
      "Epoch 280/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.6846 - accuracy: 0.4935\n",
      "Epoch 281/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.6859 - accuracy: 0.4935\n",
      "Epoch 282/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.6874 - accuracy: 0.4935\n",
      "Epoch 283/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.6888 - accuracy: 0.4935\n",
      "Epoch 284/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.6902 - accuracy: 0.4935\n",
      "Epoch 285/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.6916 - accuracy: 0.4935\n",
      "Epoch 286/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.6931 - accuracy: 0.4935\n",
      "Epoch 287/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.6945 - accuracy: 0.4935\n",
      "Epoch 288/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.6960 - accuracy: 0.4935\n",
      "Epoch 289/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.6974 - accuracy: 0.4935\n",
      "Epoch 290/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.6989 - accuracy: 0.4935\n",
      "Epoch 291/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7004 - accuracy: 0.4935\n",
      "Epoch 292/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7018 - accuracy: 0.4935\n",
      "Epoch 293/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7033 - accuracy: 0.4935\n",
      "Epoch 294/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7048 - accuracy: 0.4935\n",
      "Epoch 295/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7062 - accuracy: 0.4935\n",
      "Epoch 296/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7077 - accuracy: 0.4935\n",
      "Epoch 297/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7091 - accuracy: 0.4935\n",
      "Epoch 298/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7106 - accuracy: 0.4935\n",
      "Epoch 299/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7120 - accuracy: 0.4935\n",
      "Epoch 300/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7134 - accuracy: 0.4935\n",
      "Epoch 301/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7148 - accuracy: 0.4935\n",
      "Epoch 302/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7162 - accuracy: 0.4935\n",
      "Epoch 303/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7176 - accuracy: 0.4935\n",
      "Epoch 304/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7190 - accuracy: 0.4935\n",
      "Epoch 305/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7205 - accuracy: 0.4935\n",
      "Epoch 306/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7218 - accuracy: 0.4935\n",
      "Epoch 307/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7233 - accuracy: 0.4935\n",
      "Epoch 308/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7248 - accuracy: 0.4935\n",
      "Epoch 309/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.7262 - accuracy: 0.4935\n",
      "Epoch 310/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7277 - accuracy: 0.4935\n",
      "Epoch 311/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7291 - accuracy: 0.4935\n",
      "Epoch 312/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.7305 - accuracy: 0.4935\n",
      "Epoch 313/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7319 - accuracy: 0.4935\n",
      "Epoch 314/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: -1.7334 - accuracy: 0.4935\n",
      "Epoch 315/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7348 - accuracy: 0.4935\n",
      "Epoch 316/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7363 - accuracy: 0.4935\n",
      "Epoch 317/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7377 - accuracy: 0.4935\n",
      "Epoch 318/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.7391 - accuracy: 0.4935\n",
      "Epoch 319/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7406 - accuracy: 0.4935\n",
      "Epoch 320/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7420 - accuracy: 0.4935\n",
      "Epoch 321/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.7434 - accuracy: 0.4935\n",
      "Epoch 322/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7449 - accuracy: 0.4935\n",
      "Epoch 323/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.7464 - accuracy: 0.4935\n",
      "Epoch 324/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7478 - accuracy: 0.4935\n",
      "Epoch 325/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7493 - accuracy: 0.4935\n",
      "Epoch 326/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7508 - accuracy: 0.4935\n",
      "Epoch 327/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.7522 - accuracy: 0.4935\n",
      "Epoch 328/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7537 - accuracy: 0.4935\n",
      "Epoch 329/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7551 - accuracy: 0.4935\n",
      "Epoch 330/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7565 - accuracy: 0.4935\n",
      "Epoch 331/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7580 - accuracy: 0.4935\n",
      "Epoch 332/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7594 - accuracy: 0.4935\n",
      "Epoch 333/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7608 - accuracy: 0.4935\n",
      "Epoch 334/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: -1.7623 - accuracy: 0.4935\n",
      "Epoch 335/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.7637 - accuracy: 0.4935\n",
      "Epoch 336/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.7652 - accuracy: 0.4935\n",
      "Epoch 337/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.7666 - accuracy: 0.4935\n",
      "Epoch 338/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7680 - accuracy: 0.4935\n",
      "Epoch 339/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7695 - accuracy: 0.4935\n",
      "Epoch 340/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7709 - accuracy: 0.4935\n",
      "Epoch 341/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.7724 - accuracy: 0.4935\n",
      "Epoch 342/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7738 - accuracy: 0.4935\n",
      "Epoch 343/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7753 - accuracy: 0.4935\n",
      "Epoch 344/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7767 - accuracy: 0.4935\n",
      "Epoch 345/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.7782 - accuracy: 0.4935\n",
      "Epoch 346/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7795 - accuracy: 0.4935\n",
      "Epoch 347/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7811 - accuracy: 0.4935\n",
      "Epoch 348/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.7825 - accuracy: 0.4935\n",
      "Epoch 349/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7839 - accuracy: 0.4935\n",
      "Epoch 350/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.7854 - accuracy: 0.4935\n",
      "Epoch 351/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.7869 - accuracy: 0.4935\n",
      "Epoch 352/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.7883 - accuracy: 0.4935\n",
      "Epoch 353/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7898 - accuracy: 0.4935\n",
      "Epoch 354/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.7912 - accuracy: 0.4935\n",
      "Epoch 355/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7927 - accuracy: 0.4935\n",
      "Epoch 356/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7941 - accuracy: 0.4935\n",
      "Epoch 357/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7955 - accuracy: 0.4935\n",
      "Epoch 358/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7969 - accuracy: 0.4935\n",
      "Epoch 359/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.7983 - accuracy: 0.4935\n",
      "Epoch 360/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.7997 - accuracy: 0.4935\n",
      "Epoch 361/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.8010 - accuracy: 0.4935\n",
      "Epoch 362/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8025 - accuracy: 0.4935\n",
      "Epoch 363/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8038 - accuracy: 0.4935\n",
      "Epoch 364/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.8053 - accuracy: 0.4935\n",
      "Epoch 365/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8067 - accuracy: 0.4935\n",
      "Epoch 366/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8081 - accuracy: 0.4935\n",
      "Epoch 367/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8095 - accuracy: 0.4935\n",
      "Epoch 368/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8109 - accuracy: 0.4935\n",
      "Epoch 369/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8123 - accuracy: 0.4935\n",
      "Epoch 370/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8139 - accuracy: 0.4935\n",
      "Epoch 371/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8152 - accuracy: 0.4935\n",
      "Epoch 372/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8167 - accuracy: 0.4935\n",
      "Epoch 373/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.8181 - accuracy: 0.4935\n",
      "Epoch 374/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8196 - accuracy: 0.4935\n",
      "Epoch 375/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.8210 - accuracy: 0.4935\n",
      "Epoch 376/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8224 - accuracy: 0.4935\n",
      "Epoch 377/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8238 - accuracy: 0.4935\n",
      "Epoch 378/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8252 - accuracy: 0.4935\n",
      "Epoch 379/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.8267 - accuracy: 0.4935\n",
      "Epoch 380/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8281 - accuracy: 0.4935\n",
      "Epoch 381/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8296 - accuracy: 0.4935\n",
      "Epoch 382/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8310 - accuracy: 0.4935\n",
      "Epoch 383/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.8325 - accuracy: 0.4935\n",
      "Epoch 384/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8339 - accuracy: 0.4935\n",
      "Epoch 385/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8354 - accuracy: 0.4935\n",
      "Epoch 386/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8369 - accuracy: 0.4935\n",
      "Epoch 387/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8383 - accuracy: 0.4935\n",
      "Epoch 388/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8397 - accuracy: 0.4935\n",
      "Epoch 389/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8412 - accuracy: 0.4935\n",
      "Epoch 390/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.8426 - accuracy: 0.4935\n",
      "Epoch 391/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8442 - accuracy: 0.4935\n",
      "Epoch 392/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8456 - accuracy: 0.4935\n",
      "Epoch 393/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8470 - accuracy: 0.4935\n",
      "Epoch 394/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8485 - accuracy: 0.4935\n",
      "Epoch 395/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8499 - accuracy: 0.4935\n",
      "Epoch 396/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8513 - accuracy: 0.4935\n",
      "Epoch 397/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.8528 - accuracy: 0.4935\n",
      "Epoch 398/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.8542 - accuracy: 0.4935\n",
      "Epoch 399/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.8557 - accuracy: 0.4935\n",
      "Epoch 400/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8571 - accuracy: 0.4935\n",
      "Epoch 401/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.8585 - accuracy: 0.4935\n",
      "Epoch 402/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8599 - accuracy: 0.4935\n",
      "Epoch 403/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8614 - accuracy: 0.4935\n",
      "Epoch 404/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8628 - accuracy: 0.4935\n",
      "Epoch 405/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8643 - accuracy: 0.4935\n",
      "Epoch 406/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8658 - accuracy: 0.4935\n",
      "Epoch 407/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8672 - accuracy: 0.4935\n",
      "Epoch 408/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8688 - accuracy: 0.4935\n",
      "Epoch 409/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8701 - accuracy: 0.4935\n",
      "Epoch 410/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8716 - accuracy: 0.4935\n",
      "Epoch 411/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8730 - accuracy: 0.4935\n",
      "Epoch 412/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8744 - accuracy: 0.4935\n",
      "Epoch 413/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8759 - accuracy: 0.4935\n",
      "Epoch 414/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8773 - accuracy: 0.4935\n",
      "Epoch 415/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.8787 - accuracy: 0.4935\n",
      "Epoch 416/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.8801 - accuracy: 0.4935\n",
      "Epoch 417/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8816 - accuracy: 0.4935\n",
      "Epoch 418/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8830 - accuracy: 0.4935\n",
      "Epoch 419/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8844 - accuracy: 0.4935\n",
      "Epoch 420/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.8859 - accuracy: 0.4935\n",
      "Epoch 421/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.8873 - accuracy: 0.4935\n",
      "Epoch 422/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.8888 - accuracy: 0.4935\n",
      "Epoch 423/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8903 - accuracy: 0.4935\n",
      "Epoch 424/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.8916 - accuracy: 0.4935\n",
      "Epoch 425/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.8931 - accuracy: 0.4935\n",
      "Epoch 426/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.8945 - accuracy: 0.4935\n",
      "Epoch 427/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8959 - accuracy: 0.4935\n",
      "Epoch 428/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8975 - accuracy: 0.4935\n",
      "Epoch 429/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.8989 - accuracy: 0.4935\n",
      "Epoch 430/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9002 - accuracy: 0.4935\n",
      "Epoch 431/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9018 - accuracy: 0.4935\n",
      "Epoch 432/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.9031 - accuracy: 0.4935\n",
      "Epoch 433/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9046 - accuracy: 0.4935\n",
      "Epoch 434/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.9061 - accuracy: 0.4935\n",
      "Epoch 435/1000\n",
      "3/3 [==============================] - 0s 6ms/step - loss: -1.9074 - accuracy: 0.4935\n",
      "Epoch 436/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: -1.9089 - accuracy: 0.4935\n",
      "Epoch 437/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.9102 - accuracy: 0.4935\n",
      "Epoch 438/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9117 - accuracy: 0.4935\n",
      "Epoch 439/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.9130 - accuracy: 0.4935\n",
      "Epoch 440/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9145 - accuracy: 0.4935\n",
      "Epoch 441/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.9158 - accuracy: 0.4935\n",
      "Epoch 442/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9173 - accuracy: 0.4935\n",
      "Epoch 443/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.9187 - accuracy: 0.4935\n",
      "Epoch 444/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.9202 - accuracy: 0.4935\n",
      "Epoch 445/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9216 - accuracy: 0.4935\n",
      "Epoch 446/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.9230 - accuracy: 0.4935\n",
      "Epoch 447/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9245 - accuracy: 0.4935\n",
      "Epoch 448/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9259 - accuracy: 0.4935\n",
      "Epoch 449/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9274 - accuracy: 0.4935\n",
      "Epoch 450/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9289 - accuracy: 0.4935\n",
      "Epoch 451/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9303 - accuracy: 0.4935\n",
      "Epoch 452/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9317 - accuracy: 0.4935\n",
      "Epoch 453/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9332 - accuracy: 0.4935\n",
      "Epoch 454/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9346 - accuracy: 0.4935\n",
      "Epoch 455/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9361 - accuracy: 0.4935\n",
      "Epoch 456/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9374 - accuracy: 0.4935\n",
      "Epoch 457/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9389 - accuracy: 0.4935\n",
      "Epoch 458/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9404 - accuracy: 0.4935\n",
      "Epoch 459/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9417 - accuracy: 0.4935\n",
      "Epoch 460/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9431 - accuracy: 0.4935\n",
      "Epoch 461/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.9445 - accuracy: 0.4935\n",
      "Epoch 462/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9460 - accuracy: 0.4935\n",
      "Epoch 463/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.9474 - accuracy: 0.4935\n",
      "Epoch 464/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.9488 - accuracy: 0.4935\n",
      "Epoch 465/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9503 - accuracy: 0.4935\n",
      "Epoch 466/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9516 - accuracy: 0.4935\n",
      "Epoch 467/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9531 - accuracy: 0.4935\n",
      "Epoch 468/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9544 - accuracy: 0.4935\n",
      "Epoch 469/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9559 - accuracy: 0.4935\n",
      "Epoch 470/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9573 - accuracy: 0.4935\n",
      "Epoch 471/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9587 - accuracy: 0.4935\n",
      "Epoch 472/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9601 - accuracy: 0.4935\n",
      "Epoch 473/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9616 - accuracy: 0.4935\n",
      "Epoch 474/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9629 - accuracy: 0.4935\n",
      "Epoch 475/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9644 - accuracy: 0.4935\n",
      "Epoch 476/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9658 - accuracy: 0.4935\n",
      "Epoch 477/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9673 - accuracy: 0.4935\n",
      "Epoch 478/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9687 - accuracy: 0.4935\n",
      "Epoch 479/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9702 - accuracy: 0.4935\n",
      "Epoch 480/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9716 - accuracy: 0.4935\n",
      "Epoch 481/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9731 - accuracy: 0.4935\n",
      "Epoch 482/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9746 - accuracy: 0.4935\n",
      "Epoch 483/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9760 - accuracy: 0.4935\n",
      "Epoch 484/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9775 - accuracy: 0.4935\n",
      "Epoch 485/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9789 - accuracy: 0.4935\n",
      "Epoch 486/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9804 - accuracy: 0.4935\n",
      "Epoch 487/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9819 - accuracy: 0.4935\n",
      "Epoch 488/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9833 - accuracy: 0.4935\n",
      "Epoch 489/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9848 - accuracy: 0.4935\n",
      "Epoch 490/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9861 - accuracy: 0.4935\n",
      "Epoch 491/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9877 - accuracy: 0.4935\n",
      "Epoch 492/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9891 - accuracy: 0.4935\n",
      "Epoch 493/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.9905 - accuracy: 0.4935\n",
      "Epoch 494/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -1.9921 - accuracy: 0.4935\n",
      "Epoch 495/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9935 - accuracy: 0.4935\n",
      "Epoch 496/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9950 - accuracy: 0.4935\n",
      "Epoch 497/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9965 - accuracy: 0.4935\n",
      "Epoch 498/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9980 - accuracy: 0.4935\n",
      "Epoch 499/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -1.9994 - accuracy: 0.4935\n",
      "Epoch 500/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.0008 - accuracy: 0.4935\n",
      "Epoch 501/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0023 - accuracy: 0.4935\n",
      "Epoch 502/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: -2.0038 - accuracy: 0.4935\n",
      "Epoch 503/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0052 - accuracy: 0.4935\n",
      "Epoch 504/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0066 - accuracy: 0.4935\n",
      "Epoch 505/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0081 - accuracy: 0.4935\n",
      "Epoch 506/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0095 - accuracy: 0.4935\n",
      "Epoch 507/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0110 - accuracy: 0.4935\n",
      "Epoch 508/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0123 - accuracy: 0.4935\n",
      "Epoch 509/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0138 - accuracy: 0.4935\n",
      "Epoch 510/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0152 - accuracy: 0.4935\n",
      "Epoch 511/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0166 - accuracy: 0.4935\n",
      "Epoch 512/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0181 - accuracy: 0.4935\n",
      "Epoch 513/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0194 - accuracy: 0.4935\n",
      "Epoch 514/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.0209 - accuracy: 0.4935\n",
      "Epoch 515/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0223 - accuracy: 0.4935\n",
      "Epoch 516/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0238 - accuracy: 0.4935\n",
      "Epoch 517/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0252 - accuracy: 0.4935\n",
      "Epoch 518/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0267 - accuracy: 0.4935\n",
      "Epoch 519/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: -2.0281 - accuracy: 0.4935\n",
      "Epoch 520/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0296 - accuracy: 0.4935\n",
      "Epoch 521/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.0310 - accuracy: 0.4935\n",
      "Epoch 522/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0324 - accuracy: 0.4935\n",
      "Epoch 523/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0339 - accuracy: 0.4935\n",
      "Epoch 524/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0354 - accuracy: 0.4935\n",
      "Epoch 525/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.0368 - accuracy: 0.4935\n",
      "Epoch 526/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0382 - accuracy: 0.4935\n",
      "Epoch 527/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0397 - accuracy: 0.4935\n",
      "Epoch 528/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.0411 - accuracy: 0.4935\n",
      "Epoch 529/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0426 - accuracy: 0.4935\n",
      "Epoch 530/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0441 - accuracy: 0.4935\n",
      "Epoch 531/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.0456 - accuracy: 0.4935\n",
      "Epoch 532/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0470 - accuracy: 0.4935\n",
      "Epoch 533/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0485 - accuracy: 0.4935\n",
      "Epoch 534/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0501 - accuracy: 0.4935\n",
      "Epoch 535/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.0514 - accuracy: 0.4935\n",
      "Epoch 536/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0529 - accuracy: 0.4935\n",
      "Epoch 537/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0544 - accuracy: 0.4935\n",
      "Epoch 538/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.0558 - accuracy: 0.4935\n",
      "Epoch 539/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.0572 - accuracy: 0.4935\n",
      "Epoch 540/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0586 - accuracy: 0.4935\n",
      "Epoch 541/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0601 - accuracy: 0.4935\n",
      "Epoch 542/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0615 - accuracy: 0.4935\n",
      "Epoch 543/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0630 - accuracy: 0.4935\n",
      "Epoch 544/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0645 - accuracy: 0.4935\n",
      "Epoch 545/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0659 - accuracy: 0.4935\n",
      "Epoch 546/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0674 - accuracy: 0.4935\n",
      "Epoch 547/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0689 - accuracy: 0.4935\n",
      "Epoch 548/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0703 - accuracy: 0.4935\n",
      "Epoch 549/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0718 - accuracy: 0.4935\n",
      "Epoch 550/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0732 - accuracy: 0.4935\n",
      "Epoch 551/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0746 - accuracy: 0.4935\n",
      "Epoch 552/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0761 - accuracy: 0.4935\n",
      "Epoch 553/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.0776 - accuracy: 0.4935\n",
      "Epoch 554/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0790 - accuracy: 0.4935\n",
      "Epoch 555/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0805 - accuracy: 0.4935\n",
      "Epoch 556/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0819 - accuracy: 0.4935\n",
      "Epoch 557/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0834 - accuracy: 0.4935\n",
      "Epoch 558/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0848 - accuracy: 0.4935\n",
      "Epoch 559/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.0863 - accuracy: 0.4935\n",
      "Epoch 560/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0878 - accuracy: 0.4935\n",
      "Epoch 561/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0892 - accuracy: 0.4935\n",
      "Epoch 562/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0907 - accuracy: 0.4935\n",
      "Epoch 563/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0921 - accuracy: 0.4935\n",
      "Epoch 564/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0935 - accuracy: 0.4935\n",
      "Epoch 565/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0950 - accuracy: 0.4935\n",
      "Epoch 566/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0965 - accuracy: 0.4935\n",
      "Epoch 567/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.0980 - accuracy: 0.4935\n",
      "Epoch 568/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.0994 - accuracy: 0.4935\n",
      "Epoch 569/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.1009 - accuracy: 0.4935\n",
      "Epoch 570/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1023 - accuracy: 0.4935\n",
      "Epoch 571/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1038 - accuracy: 0.4935\n",
      "Epoch 572/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1053 - accuracy: 0.4935\n",
      "Epoch 573/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1068 - accuracy: 0.4935\n",
      "Epoch 574/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1084 - accuracy: 0.4935\n",
      "Epoch 575/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1098 - accuracy: 0.4935\n",
      "Epoch 576/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1113 - accuracy: 0.4935\n",
      "Epoch 577/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1129 - accuracy: 0.4935\n",
      "Epoch 578/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1143 - accuracy: 0.4935\n",
      "Epoch 579/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1159 - accuracy: 0.4935\n",
      "Epoch 580/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1172 - accuracy: 0.4935\n",
      "Epoch 581/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1188 - accuracy: 0.4935\n",
      "Epoch 582/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1202 - accuracy: 0.4935\n",
      "Epoch 583/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1217 - accuracy: 0.4935\n",
      "Epoch 584/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1231 - accuracy: 0.4935\n",
      "Epoch 585/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1246 - accuracy: 0.4935\n",
      "Epoch 586/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1260 - accuracy: 0.4935\n",
      "Epoch 587/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1275 - accuracy: 0.4935\n",
      "Epoch 588/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1290 - accuracy: 0.4935\n",
      "Epoch 589/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1304 - accuracy: 0.4935\n",
      "Epoch 590/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1319 - accuracy: 0.4935\n",
      "Epoch 591/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1334 - accuracy: 0.4935\n",
      "Epoch 592/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1348 - accuracy: 0.4935\n",
      "Epoch 593/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1362 - accuracy: 0.4935\n",
      "Epoch 594/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1377 - accuracy: 0.4935\n",
      "Epoch 595/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.1391 - accuracy: 0.4935\n",
      "Epoch 596/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1405 - accuracy: 0.4935\n",
      "Epoch 597/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.1420 - accuracy: 0.4935\n",
      "Epoch 598/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1435 - accuracy: 0.4935\n",
      "Epoch 599/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1449 - accuracy: 0.4935\n",
      "Epoch 600/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.1463 - accuracy: 0.4935\n",
      "Epoch 601/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1477 - accuracy: 0.4935\n",
      "Epoch 602/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1491 - accuracy: 0.4935\n",
      "Epoch 603/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1506 - accuracy: 0.4935\n",
      "Epoch 604/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1520 - accuracy: 0.4935\n",
      "Epoch 605/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1535 - accuracy: 0.4935\n",
      "Epoch 606/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.1550 - accuracy: 0.4935\n",
      "Epoch 607/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1564 - accuracy: 0.4935\n",
      "Epoch 608/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1579 - accuracy: 0.4935\n",
      "Epoch 609/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1594 - accuracy: 0.4935\n",
      "Epoch 610/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.1608 - accuracy: 0.4935\n",
      "Epoch 611/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.1622 - accuracy: 0.4935\n",
      "Epoch 612/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1636 - accuracy: 0.4935\n",
      "Epoch 613/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1651 - accuracy: 0.4935\n",
      "Epoch 614/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1666 - accuracy: 0.4935\n",
      "Epoch 615/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.1679 - accuracy: 0.4935\n",
      "Epoch 616/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: -2.1694 - accuracy: 0.4935\n",
      "Epoch 617/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: -2.1708 - accuracy: 0.4935\n",
      "Epoch 618/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1723 - accuracy: 0.4935\n",
      "Epoch 619/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1737 - accuracy: 0.4935\n",
      "Epoch 620/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1752 - accuracy: 0.4935\n",
      "Epoch 621/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1766 - accuracy: 0.4935\n",
      "Epoch 622/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1781 - accuracy: 0.4935\n",
      "Epoch 623/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1795 - accuracy: 0.4935\n",
      "Epoch 624/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1809 - accuracy: 0.4935\n",
      "Epoch 625/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1824 - accuracy: 0.4935\n",
      "Epoch 626/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1838 - accuracy: 0.4935\n",
      "Epoch 627/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1853 - accuracy: 0.4935\n",
      "Epoch 628/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1867 - accuracy: 0.4935\n",
      "Epoch 629/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1882 - accuracy: 0.4935\n",
      "Epoch 630/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1896 - accuracy: 0.4935\n",
      "Epoch 631/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1910 - accuracy: 0.4935\n",
      "Epoch 632/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1924 - accuracy: 0.4935\n",
      "Epoch 633/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1938 - accuracy: 0.4935\n",
      "Epoch 634/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1953 - accuracy: 0.4935\n",
      "Epoch 635/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1967 - accuracy: 0.4935\n",
      "Epoch 636/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1981 - accuracy: 0.4935\n",
      "Epoch 637/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.1995 - accuracy: 0.4935\n",
      "Epoch 638/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2010 - accuracy: 0.4935\n",
      "Epoch 639/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2023 - accuracy: 0.4935\n",
      "Epoch 640/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2038 - accuracy: 0.4935\n",
      "Epoch 641/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2052 - accuracy: 0.4935\n",
      "Epoch 642/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2067 - accuracy: 0.4935\n",
      "Epoch 643/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2081 - accuracy: 0.4935\n",
      "Epoch 644/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2096 - accuracy: 0.4935\n",
      "Epoch 645/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2109 - accuracy: 0.4935\n",
      "Epoch 646/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.2125 - accuracy: 0.4935\n",
      "Epoch 647/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2139 - accuracy: 0.4935\n",
      "Epoch 648/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2153 - accuracy: 0.4935\n",
      "Epoch 649/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2168 - accuracy: 0.4935\n",
      "Epoch 650/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2182 - accuracy: 0.4935\n",
      "Epoch 651/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2197 - accuracy: 0.4935\n",
      "Epoch 652/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2211 - accuracy: 0.4935\n",
      "Epoch 653/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2226 - accuracy: 0.4935\n",
      "Epoch 654/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2241 - accuracy: 0.4935\n",
      "Epoch 655/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2255 - accuracy: 0.4935\n",
      "Epoch 656/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2270 - accuracy: 0.4935\n",
      "Epoch 657/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2285 - accuracy: 0.4935\n",
      "Epoch 658/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2300 - accuracy: 0.4935\n",
      "Epoch 659/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2316 - accuracy: 0.4935\n",
      "Epoch 660/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: -2.2330 - accuracy: 0.4935\n",
      "Epoch 661/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2346 - accuracy: 0.4935\n",
      "Epoch 662/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2361 - accuracy: 0.4935\n",
      "Epoch 663/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2375 - accuracy: 0.4935\n",
      "Epoch 664/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.2391 - accuracy: 0.4935\n",
      "Epoch 665/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.2406 - accuracy: 0.4935\n",
      "Epoch 666/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: -2.2421 - accuracy: 0.4935\n",
      "Epoch 667/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2435 - accuracy: 0.4935\n",
      "Epoch 668/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2451 - accuracy: 0.4935\n",
      "Epoch 669/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2465 - accuracy: 0.4935\n",
      "Epoch 670/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2479 - accuracy: 0.4935\n",
      "Epoch 671/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2494 - accuracy: 0.4935\n",
      "Epoch 672/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2508 - accuracy: 0.4935\n",
      "Epoch 673/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2521 - accuracy: 0.4935\n",
      "Epoch 674/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2537 - accuracy: 0.4935\n",
      "Epoch 675/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2551 - accuracy: 0.4935\n",
      "Epoch 676/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2565 - accuracy: 0.4935\n",
      "Epoch 677/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2580 - accuracy: 0.4935\n",
      "Epoch 678/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2594 - accuracy: 0.4935\n",
      "Epoch 679/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2608 - accuracy: 0.4935\n",
      "Epoch 680/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2624 - accuracy: 0.4935\n",
      "Epoch 681/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.2638 - accuracy: 0.4935\n",
      "Epoch 682/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.2652 - accuracy: 0.4935\n",
      "Epoch 683/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2667 - accuracy: 0.4935\n",
      "Epoch 684/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2682 - accuracy: 0.4935\n",
      "Epoch 685/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2695 - accuracy: 0.4935\n",
      "Epoch 686/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.2709 - accuracy: 0.4935\n",
      "Epoch 687/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.2725 - accuracy: 0.4935\n",
      "Epoch 688/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2739 - accuracy: 0.4935\n",
      "Epoch 689/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2754 - accuracy: 0.4935\n",
      "Epoch 690/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2767 - accuracy: 0.4935\n",
      "Epoch 691/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2781 - accuracy: 0.4935\n",
      "Epoch 692/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2796 - accuracy: 0.4935\n",
      "Epoch 693/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2810 - accuracy: 0.4935\n",
      "Epoch 694/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2825 - accuracy: 0.4935\n",
      "Epoch 695/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.2838 - accuracy: 0.4935\n",
      "Epoch 696/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2853 - accuracy: 0.4935\n",
      "Epoch 697/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2867 - accuracy: 0.4935\n",
      "Epoch 698/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2881 - accuracy: 0.4935\n",
      "Epoch 699/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2895 - accuracy: 0.4935\n",
      "Epoch 700/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2910 - accuracy: 0.4935\n",
      "Epoch 701/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2925 - accuracy: 0.4935\n",
      "Epoch 702/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: -2.2939 - accuracy: 0.4935\n",
      "Epoch 703/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: -2.2954 - accuracy: 0.4935\n",
      "Epoch 704/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.2968 - accuracy: 0.4935\n",
      "Epoch 705/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2983 - accuracy: 0.4935\n",
      "Epoch 706/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.2997 - accuracy: 0.4935\n",
      "Epoch 707/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3013 - accuracy: 0.4935\n",
      "Epoch 708/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3027 - accuracy: 0.4935\n",
      "Epoch 709/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3041 - accuracy: 0.4935\n",
      "Epoch 710/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.3056 - accuracy: 0.4935\n",
      "Epoch 711/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3071 - accuracy: 0.4935\n",
      "Epoch 712/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.3085 - accuracy: 0.4935\n",
      "Epoch 713/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3099 - accuracy: 0.4935\n",
      "Epoch 714/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3114 - accuracy: 0.4935\n",
      "Epoch 715/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3128 - accuracy: 0.4935\n",
      "Epoch 716/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.3143 - accuracy: 0.4935\n",
      "Epoch 717/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3157 - accuracy: 0.4935\n",
      "Epoch 718/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.3172 - accuracy: 0.4935\n",
      "Epoch 719/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.3186 - accuracy: 0.4935\n",
      "Epoch 720/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.3201 - accuracy: 0.4935\n",
      "Epoch 721/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.3216 - accuracy: 0.4935\n",
      "Epoch 722/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3231 - accuracy: 0.4935\n",
      "Epoch 723/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3245 - accuracy: 0.4935\n",
      "Epoch 724/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3260 - accuracy: 0.4935\n",
      "Epoch 725/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3274 - accuracy: 0.4935\n",
      "Epoch 726/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3289 - accuracy: 0.4935\n",
      "Epoch 727/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3304 - accuracy: 0.4935\n",
      "Epoch 728/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3318 - accuracy: 0.4935\n",
      "Epoch 729/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3333 - accuracy: 0.4935\n",
      "Epoch 730/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3348 - accuracy: 0.4935\n",
      "Epoch 731/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3362 - accuracy: 0.4935\n",
      "Epoch 732/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3376 - accuracy: 0.4935\n",
      "Epoch 733/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3392 - accuracy: 0.4935\n",
      "Epoch 734/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3406 - accuracy: 0.4935\n",
      "Epoch 735/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3421 - accuracy: 0.4935\n",
      "Epoch 736/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3436 - accuracy: 0.4935\n",
      "Epoch 737/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3449 - accuracy: 0.4935\n",
      "Epoch 738/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3465 - accuracy: 0.4935\n",
      "Epoch 739/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3480 - accuracy: 0.4935\n",
      "Epoch 740/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3494 - accuracy: 0.4935\n",
      "Epoch 741/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3507 - accuracy: 0.4935\n",
      "Epoch 742/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3523 - accuracy: 0.4935\n",
      "Epoch 743/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.3538 - accuracy: 0.4935\n",
      "Epoch 744/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3551 - accuracy: 0.4935\n",
      "Epoch 745/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3567 - accuracy: 0.4935\n",
      "Epoch 746/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3581 - accuracy: 0.4935\n",
      "Epoch 747/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3595 - accuracy: 0.4935\n",
      "Epoch 748/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3610 - accuracy: 0.4935\n",
      "Epoch 749/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3625 - accuracy: 0.4935\n",
      "Epoch 750/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3640 - accuracy: 0.4935\n",
      "Epoch 751/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3655 - accuracy: 0.4935\n",
      "Epoch 752/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3669 - accuracy: 0.4935\n",
      "Epoch 753/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3683 - accuracy: 0.4935\n",
      "Epoch 754/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3698 - accuracy: 0.4935\n",
      "Epoch 755/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3712 - accuracy: 0.4935\n",
      "Epoch 756/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.3727 - accuracy: 0.4935\n",
      "Epoch 757/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3741 - accuracy: 0.4935\n",
      "Epoch 758/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3755 - accuracy: 0.4935\n",
      "Epoch 759/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3769 - accuracy: 0.4935\n",
      "Epoch 760/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3784 - accuracy: 0.4935\n",
      "Epoch 761/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3798 - accuracy: 0.4935\n",
      "Epoch 762/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3814 - accuracy: 0.4935\n",
      "Epoch 763/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3828 - accuracy: 0.4935\n",
      "Epoch 764/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3843 - accuracy: 0.4935\n",
      "Epoch 765/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3857 - accuracy: 0.4935\n",
      "Epoch 766/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3872 - accuracy: 0.4935\n",
      "Epoch 767/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3887 - accuracy: 0.4935\n",
      "Epoch 768/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3902 - accuracy: 0.4935\n",
      "Epoch 769/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3917 - accuracy: 0.4935\n",
      "Epoch 770/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3932 - accuracy: 0.4935\n",
      "Epoch 771/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3947 - accuracy: 0.4935\n",
      "Epoch 772/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3961 - accuracy: 0.4935\n",
      "Epoch 773/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3977 - accuracy: 0.4935\n",
      "Epoch 774/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.3991 - accuracy: 0.4935\n",
      "Epoch 775/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4006 - accuracy: 0.4935\n",
      "Epoch 776/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4022 - accuracy: 0.4935\n",
      "Epoch 777/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: -2.4036 - accuracy: 0.4935\n",
      "Epoch 778/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.4051 - accuracy: 0.4935\n",
      "Epoch 779/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4066 - accuracy: 0.4935\n",
      "Epoch 780/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4080 - accuracy: 0.4935\n",
      "Epoch 781/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4095 - accuracy: 0.4935\n",
      "Epoch 782/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4109 - accuracy: 0.4935\n",
      "Epoch 783/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4124 - accuracy: 0.4935\n",
      "Epoch 784/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4139 - accuracy: 0.4935\n",
      "Epoch 785/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4153 - accuracy: 0.4935\n",
      "Epoch 786/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4169 - accuracy: 0.4935\n",
      "Epoch 787/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4183 - accuracy: 0.4935\n",
      "Epoch 788/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4198 - accuracy: 0.4935\n",
      "Epoch 789/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4213 - accuracy: 0.4935\n",
      "Epoch 790/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4226 - accuracy: 0.4935\n",
      "Epoch 791/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4242 - accuracy: 0.4935\n",
      "Epoch 792/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4257 - accuracy: 0.4935\n",
      "Epoch 793/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4271 - accuracy: 0.4935\n",
      "Epoch 794/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4286 - accuracy: 0.4935\n",
      "Epoch 795/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4300 - accuracy: 0.4935\n",
      "Epoch 796/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.4314 - accuracy: 0.4935\n",
      "Epoch 797/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4329 - accuracy: 0.4935\n",
      "Epoch 798/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4344 - accuracy: 0.4935\n",
      "Epoch 799/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4358 - accuracy: 0.4935\n",
      "Epoch 800/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4372 - accuracy: 0.4935\n",
      "Epoch 801/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4386 - accuracy: 0.4935\n",
      "Epoch 802/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4402 - accuracy: 0.4935\n",
      "Epoch 803/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4416 - accuracy: 0.4935\n",
      "Epoch 804/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4430 - accuracy: 0.4935\n",
      "Epoch 805/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4445 - accuracy: 0.4935\n",
      "Epoch 806/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4460 - accuracy: 0.4935\n",
      "Epoch 807/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4474 - accuracy: 0.4935\n",
      "Epoch 808/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4489 - accuracy: 0.4935\n",
      "Epoch 809/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4504 - accuracy: 0.4935\n",
      "Epoch 810/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4518 - accuracy: 0.4935\n",
      "Epoch 811/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4532 - accuracy: 0.4935\n",
      "Epoch 812/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4547 - accuracy: 0.4935\n",
      "Epoch 813/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4561 - accuracy: 0.4935\n",
      "Epoch 814/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4575 - accuracy: 0.4935\n",
      "Epoch 815/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4590 - accuracy: 0.4935\n",
      "Epoch 816/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4603 - accuracy: 0.4935\n",
      "Epoch 817/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4618 - accuracy: 0.4935\n",
      "Epoch 818/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4633 - accuracy: 0.4935\n",
      "Epoch 819/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4647 - accuracy: 0.4935\n",
      "Epoch 820/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4662 - accuracy: 0.4935\n",
      "Epoch 821/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4677 - accuracy: 0.4935\n",
      "Epoch 822/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4691 - accuracy: 0.4935\n",
      "Epoch 823/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4705 - accuracy: 0.4935\n",
      "Epoch 824/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4720 - accuracy: 0.4935\n",
      "Epoch 825/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4735 - accuracy: 0.4935\n",
      "Epoch 826/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4749 - accuracy: 0.4935\n",
      "Epoch 827/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4764 - accuracy: 0.4935\n",
      "Epoch 828/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4779 - accuracy: 0.4935\n",
      "Epoch 829/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.4793 - accuracy: 0.4935\n",
      "Epoch 830/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.4808 - accuracy: 0.4935\n",
      "Epoch 831/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.4824 - accuracy: 0.4935\n",
      "Epoch 832/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4838 - accuracy: 0.4935\n",
      "Epoch 833/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4852 - accuracy: 0.4935\n",
      "Epoch 834/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4868 - accuracy: 0.4935\n",
      "Epoch 835/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4883 - accuracy: 0.4935\n",
      "Epoch 836/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4896 - accuracy: 0.4935\n",
      "Epoch 837/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4911 - accuracy: 0.4935\n",
      "Epoch 838/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4926 - accuracy: 0.4935\n",
      "Epoch 839/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4941 - accuracy: 0.4935\n",
      "Epoch 840/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4955 - accuracy: 0.4935\n",
      "Epoch 841/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.4970 - accuracy: 0.4935\n",
      "Epoch 842/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.4985 - accuracy: 0.4935\n",
      "Epoch 843/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5000 - accuracy: 0.4935\n",
      "Epoch 844/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5016 - accuracy: 0.4935\n",
      "Epoch 845/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5030 - accuracy: 0.4935\n",
      "Epoch 846/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5045 - accuracy: 0.4935\n",
      "Epoch 847/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5060 - accuracy: 0.4935\n",
      "Epoch 848/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5074 - accuracy: 0.4935\n",
      "Epoch 849/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.5090 - accuracy: 0.4935\n",
      "Epoch 850/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5104 - accuracy: 0.4935\n",
      "Epoch 851/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: -2.5118 - accuracy: 0.4935\n",
      "Epoch 852/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.5133 - accuracy: 0.4935\n",
      "Epoch 853/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5148 - accuracy: 0.4935\n",
      "Epoch 854/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5162 - accuracy: 0.4935\n",
      "Epoch 855/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: -2.5176 - accuracy: 0.4935\n",
      "Epoch 856/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.5191 - accuracy: 0.4935\n",
      "Epoch 857/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5205 - accuracy: 0.4935\n",
      "Epoch 858/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5219 - accuracy: 0.4935\n",
      "Epoch 859/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5233 - accuracy: 0.4935\n",
      "Epoch 860/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5247 - accuracy: 0.4935\n",
      "Epoch 861/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5262 - accuracy: 0.4935\n",
      "Epoch 862/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.5275 - accuracy: 0.4935\n",
      "Epoch 863/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.5291 - accuracy: 0.4935\n",
      "Epoch 864/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.5305 - accuracy: 0.4935\n",
      "Epoch 865/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.5319 - accuracy: 0.4935\n",
      "Epoch 866/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5334 - accuracy: 0.4935\n",
      "Epoch 867/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5348 - accuracy: 0.4935\n",
      "Epoch 868/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.5364 - accuracy: 0.4935\n",
      "Epoch 869/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5378 - accuracy: 0.4935\n",
      "Epoch 870/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5393 - accuracy: 0.4935\n",
      "Epoch 871/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5408 - accuracy: 0.4935\n",
      "Epoch 872/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5423 - accuracy: 0.4935\n",
      "Epoch 873/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.5438 - accuracy: 0.4935\n",
      "Epoch 874/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.5453 - accuracy: 0.4935\n",
      "Epoch 875/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5467 - accuracy: 0.4935\n",
      "Epoch 876/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5482 - accuracy: 0.4935\n",
      "Epoch 877/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5497 - accuracy: 0.4935\n",
      "Epoch 878/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5512 - accuracy: 0.4935\n",
      "Epoch 879/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5526 - accuracy: 0.4935\n",
      "Epoch 880/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.5541 - accuracy: 0.4935\n",
      "Epoch 881/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5556 - accuracy: 0.4935\n",
      "Epoch 882/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5571 - accuracy: 0.4935\n",
      "Epoch 883/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5585 - accuracy: 0.4935\n",
      "Epoch 884/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.5600 - accuracy: 0.4935\n",
      "Epoch 885/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5615 - accuracy: 0.4935\n",
      "Epoch 886/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5630 - accuracy: 0.4935\n",
      "Epoch 887/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5643 - accuracy: 0.4935\n",
      "Epoch 888/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5658 - accuracy: 0.4935\n",
      "Epoch 889/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.5673 - accuracy: 0.4935\n",
      "Epoch 890/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5688 - accuracy: 0.4935\n",
      "Epoch 891/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5703 - accuracy: 0.4935\n",
      "Epoch 892/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5717 - accuracy: 0.4935\n",
      "Epoch 893/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5732 - accuracy: 0.4935\n",
      "Epoch 894/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5746 - accuracy: 0.4935\n",
      "Epoch 895/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: -2.5761 - accuracy: 0.4935\n",
      "Epoch 896/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5775 - accuracy: 0.4935\n",
      "Epoch 897/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5790 - accuracy: 0.4935\n",
      "Epoch 898/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5805 - accuracy: 0.4935\n",
      "Epoch 899/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5820 - accuracy: 0.4935\n",
      "Epoch 900/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.5835 - accuracy: 0.4935\n",
      "Epoch 901/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5850 - accuracy: 0.4935\n",
      "Epoch 902/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5865 - accuracy: 0.4935\n",
      "Epoch 903/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5879 - accuracy: 0.4935\n",
      "Epoch 904/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5894 - accuracy: 0.4935\n",
      "Epoch 905/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5909 - accuracy: 0.4935\n",
      "Epoch 906/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5924 - accuracy: 0.4935\n",
      "Epoch 907/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5938 - accuracy: 0.4935\n",
      "Epoch 908/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5953 - accuracy: 0.4935\n",
      "Epoch 909/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5967 - accuracy: 0.4935\n",
      "Epoch 910/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5981 - accuracy: 0.4935\n",
      "Epoch 911/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.5995 - accuracy: 0.4935\n",
      "Epoch 912/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6010 - accuracy: 0.4935\n",
      "Epoch 913/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6025 - accuracy: 0.4935\n",
      "Epoch 914/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6039 - accuracy: 0.4935\n",
      "Epoch 915/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6054 - accuracy: 0.4935\n",
      "Epoch 916/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6069 - accuracy: 0.4935\n",
      "Epoch 917/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6083 - accuracy: 0.4935\n",
      "Epoch 918/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6098 - accuracy: 0.4935\n",
      "Epoch 919/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6112 - accuracy: 0.4935\n",
      "Epoch 920/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: -2.6127 - accuracy: 0.4935\n",
      "Epoch 921/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.6142 - accuracy: 0.4935\n",
      "Epoch 922/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6156 - accuracy: 0.4935\n",
      "Epoch 923/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6171 - accuracy: 0.4935\n",
      "Epoch 924/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6185 - accuracy: 0.4935\n",
      "Epoch 925/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6200 - accuracy: 0.4935\n",
      "Epoch 926/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6215 - accuracy: 0.4935\n",
      "Epoch 927/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6230 - accuracy: 0.4935\n",
      "Epoch 928/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6244 - accuracy: 0.4935\n",
      "Epoch 929/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6259 - accuracy: 0.4935\n",
      "Epoch 930/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6272 - accuracy: 0.4935\n",
      "Epoch 931/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6287 - accuracy: 0.4935\n",
      "Epoch 932/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6301 - accuracy: 0.4935\n",
      "Epoch 933/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6316 - accuracy: 0.4935\n",
      "Epoch 934/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6330 - accuracy: 0.4935\n",
      "Epoch 935/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.6343 - accuracy: 0.4935\n",
      "Epoch 936/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6357 - accuracy: 0.4935\n",
      "Epoch 937/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6370 - accuracy: 0.4935\n",
      "Epoch 938/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6385 - accuracy: 0.4935\n",
      "Epoch 939/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6398 - accuracy: 0.4935\n",
      "Epoch 940/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6413 - accuracy: 0.4935\n",
      "Epoch 941/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6427 - accuracy: 0.4935\n",
      "Epoch 942/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6441 - accuracy: 0.4935\n",
      "Epoch 943/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6456 - accuracy: 0.4935\n",
      "Epoch 944/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6471 - accuracy: 0.4935\n",
      "Epoch 945/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.6485 - accuracy: 0.4935\n",
      "Epoch 946/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.6500 - accuracy: 0.4935\n",
      "Epoch 947/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6515 - accuracy: 0.4935\n",
      "Epoch 948/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6530 - accuracy: 0.4935\n",
      "Epoch 949/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6546 - accuracy: 0.4935\n",
      "Epoch 950/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6560 - accuracy: 0.4935\n",
      "Epoch 951/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6575 - accuracy: 0.4935\n",
      "Epoch 952/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6590 - accuracy: 0.4935\n",
      "Epoch 953/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6604 - accuracy: 0.4935\n",
      "Epoch 954/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6619 - accuracy: 0.4935\n",
      "Epoch 955/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6634 - accuracy: 0.4935\n",
      "Epoch 956/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6649 - accuracy: 0.4935\n",
      "Epoch 957/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6664 - accuracy: 0.4935\n",
      "Epoch 958/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6679 - accuracy: 0.4935\n",
      "Epoch 959/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6694 - accuracy: 0.4935\n",
      "Epoch 960/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6708 - accuracy: 0.4935\n",
      "Epoch 961/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6723 - accuracy: 0.4935\n",
      "Epoch 962/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6738 - accuracy: 0.4935\n",
      "Epoch 963/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6753 - accuracy: 0.4935\n",
      "Epoch 964/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6768 - accuracy: 0.4935\n",
      "Epoch 965/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.6782 - accuracy: 0.4935\n",
      "Epoch 966/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6797 - accuracy: 0.4935\n",
      "Epoch 967/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6812 - accuracy: 0.4935\n",
      "Epoch 968/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6827 - accuracy: 0.4935\n",
      "Epoch 969/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6842 - accuracy: 0.4935\n",
      "Epoch 970/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6857 - accuracy: 0.4935\n",
      "Epoch 971/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6872 - accuracy: 0.4935\n",
      "Epoch 972/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6887 - accuracy: 0.4935\n",
      "Epoch 973/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6902 - accuracy: 0.4935\n",
      "Epoch 974/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6916 - accuracy: 0.4935\n",
      "Epoch 975/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6932 - accuracy: 0.4935\n",
      "Epoch 976/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6947 - accuracy: 0.4935\n",
      "Epoch 977/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.6961 - accuracy: 0.4935\n",
      "Epoch 978/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6976 - accuracy: 0.4935\n",
      "Epoch 979/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.6990 - accuracy: 0.4935\n",
      "Epoch 980/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.7004 - accuracy: 0.4935\n",
      "Epoch 981/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.7019 - accuracy: 0.4935\n",
      "Epoch 982/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.7034 - accuracy: 0.4935\n",
      "Epoch 983/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.7048 - accuracy: 0.4935\n",
      "Epoch 984/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.7062 - accuracy: 0.4935\n",
      "Epoch 985/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.7077 - accuracy: 0.4935\n",
      "Epoch 986/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.7091 - accuracy: 0.4935\n",
      "Epoch 987/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -2.7106 - accuracy: 0.4935\n",
      "Epoch 988/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.7121 - accuracy: 0.4935\n",
      "Epoch 989/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.7134 - accuracy: 0.4935\n",
      "Epoch 990/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.7149 - accuracy: 0.4935\n",
      "Epoch 991/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.7165 - accuracy: 0.4935\n",
      "Epoch 992/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.7179 - accuracy: 0.4935\n",
      "Epoch 993/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.7193 - accuracy: 0.4935\n",
      "Epoch 994/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.7208 - accuracy: 0.4935\n",
      "Epoch 995/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.7223 - accuracy: 0.4935\n",
      "Epoch 996/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.7238 - accuracy: 0.4935\n",
      "Epoch 997/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.7253 - accuracy: 0.4935\n",
      "Epoch 998/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.7267 - accuracy: 0.4935\n",
      "Epoch 999/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.7282 - accuracy: 0.4935\n",
      "Epoch 1000/1000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -2.7297 - accuracy: 0.4935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8f08154970>"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
